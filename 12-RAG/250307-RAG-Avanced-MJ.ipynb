{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /Users/minjeong/Library/Caches/pypoetry/virtualenvs/langchain-kr-szXyjQUn-py3.11/lib/python3.11/site-packages (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /Users/minjeong/Library/Caches/pypoetry/virtualenvs/langchain-kr-szXyjQUn-py3.11/lib/python3.11/site-packages (from pymupdf) (1.24.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: data/CHI_2025_LBW_Korlingma.pdf\n",
      "============================================================\n",
      "[HUMAN]\n",
      "Who is the author of this paper?\n",
      "\n",
      "[AI]\n",
      "The author of the paper is Choi and Shin et al.\n"
     ]
    }
   ],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "file_path = \"data/CHI_2025_LBW_Korlingma.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 단계 4: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 5: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 단계 6: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 단계 7: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"Who is the author of this paper?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: data/CHI_2025_LBW_Korlingma.pdf\n",
      "============================================================\n",
      "[HUMAN]\n",
      "이 논문의 findings를 요약해주세요\n",
      "\n",
      "[AI]\n",
      "This study investigated the role of Pragmatic Markers (PMs) in Korean Voice-based Conversational Agents (VCAs) and found that strategic PM implementation can enhance conversational naturalness and emotional engagement. The findings suggest that PMs can improve trust, relatability, and adaptiveness while reducing cognitive load for users. However, inappropriate use of PMs can negatively impact user experience, highlighting the need for careful integration in conversational agents.\n"
     ]
    }
   ],
   "source": [
    "question = \"이 논문의 findings를 요약해주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-MAN8Kwi6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
